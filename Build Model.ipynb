{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy.stats as sps\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('all_candidate_variabels.csv')\n",
    "data = data.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_final = pd.read_csv('final_vars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = data[data.date < '2016-11-01']\n",
    "oot = data[data.date > '2016-11-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_test = train_test['fraud_label']\n",
    "y_oot = oot['fraud_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[list(vars_final['variable'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_test = train_test[list(vars_final['variable'].values)]\n",
    "x_oot = oot[list(vars_final['variable'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(x)\n",
    "x_train_test = scaler.transform(x_train_test)\n",
    "x_oot = scaler.transform(x_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FDR(df):\n",
    "    topRows = int(round(len(df)*0.03))\n",
    "    bads = df.loc[df['fraud_label'] == 1]\n",
    "    numbads = len(bads)\n",
    "    \n",
    "    temp = df[['fraud_proba','fraud_label']].copy()\n",
    "    temp0 = temp.sort_values('fraud_proba',ascending=False)\n",
    "    temp1 = temp0.head(topRows)\n",
    "    temp2 = temp0.tail(topRows)\n",
    "    needed1 = temp1.loc[:,'fraud_label']\n",
    "    needed2 = temp2.loc[:,'fraud_label']\n",
    "    FDR1 = sum(needed1)/numbads\n",
    "    FDR2 = sum(needed2)/numbads\n",
    "    FDRate = np.maximum(FDR1,FDR2) \n",
    "    \n",
    "    return FDRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log = []\n",
    "\n",
    "for size in [0.3,0.4]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        x_train_test, y_train_test, test_size = size, random_state = 0)\n",
    "    for c in [0.001,0.01,0.1,1,10]:\n",
    "        model = LogisticRegression(penalty = 'l2', solver='lbfgs', class_weight = 'balanced', C = c)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_hat = clf.predict_proba(X_train)\n",
    "        train = pd.DataFrame(X_train, columns = list(vars_final['variable'].values))\n",
    "        train['fraud_label'] = y_train.values\n",
    "        train['fraud_proba'] = y_train_hat[:,1]\n",
    "        train_fdr = FDR(train)\n",
    "\n",
    "        y_test_hat = clf.predict_proba(X_test)\n",
    "        test = pd.DataFrame(X_test, columns = list(vars_final['variable'].values))\n",
    "        test['fraud_label'] = y_test.values\n",
    "        test['fraud_proba'] = y_test_hat[:,1]\n",
    "        test_fdr = FDR(test)\n",
    "\n",
    "        y_oot_hat = clf.predict_proba(x_oot)\n",
    "        oot = pd.DataFrame(x_oot, columns = list(vars_final['variable'].values))\n",
    "        oot['fraud_label'] = y_oot.values\n",
    "        oot['fraud_proba'] = y_oot_hat[:,1]\n",
    "        oot_fdr = FDR(oot)\n",
    "        \n",
    "        dict_log = dict(test_size = size, regularization_para = c, TRAIN = train_fdr, TEST = test_fdr, OOT = oot_fdr)\n",
    "        result_log.append(dict_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log = pd.DataFrame(result_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>regularization_para</th>\n",
       "      <th>TRAIN</th>\n",
       "      <th>TEST</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.563342</td>\n",
       "      <td>0.574392</td>\n",
       "      <td>0.554797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.563818</td>\n",
       "      <td>0.576881</td>\n",
       "      <td>0.556077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.564891</td>\n",
       "      <td>0.575498</td>\n",
       "      <td>0.556077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.564176</td>\n",
       "      <td>0.574945</td>\n",
       "      <td>0.556077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.564057</td>\n",
       "      <td>0.574945</td>\n",
       "      <td>0.556077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.563575</td>\n",
       "      <td>0.571017</td>\n",
       "      <td>0.554797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.566093</td>\n",
       "      <td>0.572046</td>\n",
       "      <td>0.555650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.564554</td>\n",
       "      <td>0.571017</td>\n",
       "      <td>0.555650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.564554</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.555224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.565254</td>\n",
       "      <td>0.571634</td>\n",
       "      <td>0.555224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  regularization_para     TRAIN      TEST       OOT\n",
       "0        0.3                0.001  0.563342  0.574392  0.554797\n",
       "1        0.3                0.010  0.563818  0.576881  0.556077\n",
       "2        0.3                0.100  0.564891  0.575498  0.556077\n",
       "3        0.3                1.000  0.564176  0.574945  0.556077\n",
       "4        0.3               10.000  0.564057  0.574945  0.556077\n",
       "5        0.4                0.001  0.563575  0.571017  0.554797\n",
       "6        0.4                0.010  0.566093  0.572046  0.555650\n",
       "7        0.4                0.100  0.564554  0.571017  0.555650\n",
       "8        0.4                1.000  0.564554  0.571429  0.555224\n",
       "9        0.4               10.000  0.565254  0.571634  0.555224"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_log.to_csv('result_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_nn = []\n",
    "\n",
    "for size in [0.3,0.4]:\n",
    "    for h in [(100,1),(100,2),(100,3)]:\n",
    "        for m in [50,100,200]:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                x_train_test, y_train_test, test_size = size, random_state = 0)\n",
    "            model = MLPClassifier(hidden_layer_sizes = h, max_iter = m, solver = 'adam')\n",
    "            clf = model.fit(X_train, y_train)\n",
    "\n",
    "            y_train_hat = clf.predict_proba(X_train)\n",
    "            train = pd.DataFrame(X_train, columns = list(vars_final['variable'].values))\n",
    "            train['fraud_label'] = y_train.values\n",
    "            train['fraud_proba'] = y_train_hat[:,1]\n",
    "            train_fdr = FDR(train)\n",
    "\n",
    "            y_test_hat = clf.predict_proba(X_test)\n",
    "            test = pd.DataFrame(X_test, columns = list(vars_final['variable'].values))\n",
    "            test['fraud_label'] = y_test.values\n",
    "            test['fraud_proba'] = y_test_hat[:,1]\n",
    "            test_fdr = FDR(test)\n",
    "\n",
    "            y_oot_hat = clf.predict_proba(x_oot)\n",
    "            oot = pd.DataFrame(x_oot, columns = list(vars_final['variable'].values))\n",
    "            oot['fraud_label'] = y_oot.values\n",
    "            oot['fraud_proba'] = y_oot_hat[:,1]\n",
    "            oot_fdr = FDR(oot)\n",
    "\n",
    "            dict_nn = dict(test_size = size, hidden_layer = h, epoch = m,\\\n",
    "                            TRAIN = train_fdr, TEST = test_fdr, OOT = oot_fdr)\n",
    "            result_nn.append(dict_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_nn = pd.DataFrame(result_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>hidden_layer</th>\n",
       "      <th>epoch</th>\n",
       "      <th>TRAIN</th>\n",
       "      <th>TEST</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(100, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.562746</td>\n",
       "      <td>0.572456</td>\n",
       "      <td>0.550533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(100, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>0.565725</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(100, 1)</td>\n",
       "      <td>200</td>\n",
       "      <td>0.566440</td>\n",
       "      <td>0.575498</td>\n",
       "      <td>0.554797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(100, 2)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.566798</td>\n",
       "      <td>0.574668</td>\n",
       "      <td>0.554371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(100, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>0.567990</td>\n",
       "      <td>0.576881</td>\n",
       "      <td>0.554797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(100, 2)</td>\n",
       "      <td>200</td>\n",
       "      <td>0.567394</td>\n",
       "      <td>0.576327</td>\n",
       "      <td>0.556930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(100, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.567274</td>\n",
       "      <td>0.576327</td>\n",
       "      <td>0.557356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(100, 3)</td>\n",
       "      <td>100</td>\n",
       "      <td>0.567394</td>\n",
       "      <td>0.577434</td>\n",
       "      <td>0.555224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3</td>\n",
       "      <td>(100, 3)</td>\n",
       "      <td>200</td>\n",
       "      <td>0.567394</td>\n",
       "      <td>0.575774</td>\n",
       "      <td>0.555224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(100, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.566233</td>\n",
       "      <td>0.569988</td>\n",
       "      <td>0.554797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(100, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>0.567072</td>\n",
       "      <td>0.569782</td>\n",
       "      <td>0.555224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(100, 1)</td>\n",
       "      <td>200</td>\n",
       "      <td>0.566373</td>\n",
       "      <td>0.569988</td>\n",
       "      <td>0.553092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(100, 2)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.567072</td>\n",
       "      <td>0.572664</td>\n",
       "      <td>0.556077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(100, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>0.565114</td>\n",
       "      <td>0.568547</td>\n",
       "      <td>0.555224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(100, 2)</td>\n",
       "      <td>200</td>\n",
       "      <td>0.566513</td>\n",
       "      <td>0.571017</td>\n",
       "      <td>0.556930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(100, 3)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.567632</td>\n",
       "      <td>0.570811</td>\n",
       "      <td>0.556503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(100, 3)</td>\n",
       "      <td>100</td>\n",
       "      <td>0.567772</td>\n",
       "      <td>0.571634</td>\n",
       "      <td>0.555224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(100, 3)</td>\n",
       "      <td>200</td>\n",
       "      <td>0.567632</td>\n",
       "      <td>0.570399</td>\n",
       "      <td>0.556077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_size hidden_layer  epoch     TRAIN      TEST       OOT\n",
       "0         0.3     (100, 1)     50  0.562746  0.572456  0.550533\n",
       "1         0.3     (100, 1)    100  0.565725  0.575221  0.553518\n",
       "2         0.3     (100, 1)    200  0.566440  0.575498  0.554797\n",
       "3         0.3     (100, 2)     50  0.566798  0.574668  0.554371\n",
       "4         0.3     (100, 2)    100  0.567990  0.576881  0.554797\n",
       "5         0.3     (100, 2)    200  0.567394  0.576327  0.556930\n",
       "6         0.3     (100, 3)     50  0.567274  0.576327  0.557356\n",
       "7         0.3     (100, 3)    100  0.567394  0.577434  0.555224\n",
       "8         0.3     (100, 3)    200  0.567394  0.575774  0.555224\n",
       "9         0.4     (100, 1)     50  0.566233  0.569988  0.554797\n",
       "10        0.4     (100, 1)    100  0.567072  0.569782  0.555224\n",
       "11        0.4     (100, 1)    200  0.566373  0.569988  0.553092\n",
       "12        0.4     (100, 2)     50  0.567072  0.572664  0.556077\n",
       "13        0.4     (100, 2)    100  0.565114  0.568547  0.555224\n",
       "14        0.4     (100, 2)    200  0.566513  0.571017  0.556930\n",
       "15        0.4     (100, 3)     50  0.567632  0.570811  0.556503\n",
       "16        0.4     (100, 3)    100  0.567772  0.571634  0.555224\n",
       "17        0.4     (100, 3)    200  0.567632  0.570399  0.556077"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_nn.to_csv('result_nn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rf = []\n",
    "\n",
    "for size in [0.3,0.4]:\n",
    "    for n in [50,100,150]:\n",
    "        for m in [5,7,9]:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                x_train_test, y_train_test, test_size = size, random_state = 0)\n",
    "            model = RandomForestClassifier(n_estimators = n, max_depth = m)\n",
    "            clf = model.fit(X_train, y_train)\n",
    "\n",
    "            y_train_hat = clf.predict_proba(X_train)\n",
    "            train = pd.DataFrame()\n",
    "            train['fraud_label'] = y_train.values\n",
    "            train['fraud_proba'] = y_train_hat[:,1]\n",
    "            train_fdr = FDR(train)\n",
    "\n",
    "            y_test_hat = clf.predict_proba(X_test)\n",
    "            test = pd.DataFrame()\n",
    "            test['fraud_label'] = y_test.values\n",
    "            test['fraud_proba'] = y_test_hat[:,1]\n",
    "            test_fdr = FDR(test)\n",
    "\n",
    "            y_oot_hat = clf.predict_proba(x_oot)\n",
    "            oot = pd.DataFrame()\n",
    "            oot['fraud_label'] = y_oot.values\n",
    "            oot['fraud_proba'] = y_oot_hat[:,1]\n",
    "            oot_fdr = FDR(oot)\n",
    "\n",
    "            dict_rf = dict(test_size = size, num_of_tree = n, max_depth = m,\\\n",
    "                            TRAIN = train_fdr, TEST = test_fdr, OOT = oot_fdr)\n",
    "            result_rf.append(dict_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rf = pd.DataFrame(result_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>num_of_tree</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>TRAIN</th>\n",
       "      <th>TEST</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.553093</td>\n",
       "      <td>0.565265</td>\n",
       "      <td>0.550959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.559171</td>\n",
       "      <td>0.571903</td>\n",
       "      <td>0.551812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>0.559528</td>\n",
       "      <td>0.571903</td>\n",
       "      <td>0.552665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.557979</td>\n",
       "      <td>0.570520</td>\n",
       "      <td>0.548401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.558932</td>\n",
       "      <td>0.571350</td>\n",
       "      <td>0.550107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>0.559766</td>\n",
       "      <td>0.571626</td>\n",
       "      <td>0.551812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>0.558217</td>\n",
       "      <td>0.570796</td>\n",
       "      <td>0.550107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>150</td>\n",
       "      <td>7</td>\n",
       "      <td>0.558217</td>\n",
       "      <td>0.571350</td>\n",
       "      <td>0.550107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3</td>\n",
       "      <td>150</td>\n",
       "      <td>9</td>\n",
       "      <td>0.560124</td>\n",
       "      <td>0.572456</td>\n",
       "      <td>0.551812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.554203</td>\n",
       "      <td>0.561960</td>\n",
       "      <td>0.550107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.559938</td>\n",
       "      <td>0.568135</td>\n",
       "      <td>0.550107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.4</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>0.561617</td>\n",
       "      <td>0.568753</td>\n",
       "      <td>0.553092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.553644</td>\n",
       "      <td>0.560930</td>\n",
       "      <td>0.550107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.559099</td>\n",
       "      <td>0.566077</td>\n",
       "      <td>0.550107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>0.560078</td>\n",
       "      <td>0.567312</td>\n",
       "      <td>0.551812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.4</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>0.554203</td>\n",
       "      <td>0.561136</td>\n",
       "      <td>0.550107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.4</td>\n",
       "      <td>150</td>\n",
       "      <td>7</td>\n",
       "      <td>0.559519</td>\n",
       "      <td>0.567517</td>\n",
       "      <td>0.550107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.4</td>\n",
       "      <td>150</td>\n",
       "      <td>9</td>\n",
       "      <td>0.561197</td>\n",
       "      <td>0.568341</td>\n",
       "      <td>0.551812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_size  num_of_tree  max_depth     TRAIN      TEST       OOT\n",
       "0         0.3           50          5  0.553093  0.565265  0.550959\n",
       "1         0.3           50          7  0.559171  0.571903  0.551812\n",
       "2         0.3           50          9  0.559528  0.571903  0.552665\n",
       "3         0.3          100          5  0.557979  0.570520  0.548401\n",
       "4         0.3          100          7  0.558932  0.571350  0.550107\n",
       "5         0.3          100          9  0.559766  0.571626  0.551812\n",
       "6         0.3          150          5  0.558217  0.570796  0.550107\n",
       "7         0.3          150          7  0.558217  0.571350  0.550107\n",
       "8         0.3          150          9  0.560124  0.572456  0.551812\n",
       "9         0.4           50          5  0.554203  0.561960  0.550107\n",
       "10        0.4           50          7  0.559938  0.568135  0.550107\n",
       "11        0.4           50          9  0.561617  0.568753  0.553092\n",
       "12        0.4          100          5  0.553644  0.560930  0.550107\n",
       "13        0.4          100          7  0.559099  0.566077  0.550107\n",
       "14        0.4          100          9  0.560078  0.567312  0.551812\n",
       "15        0.4          150          5  0.554203  0.561136  0.550107\n",
       "16        0.4          150          7  0.559519  0.567517  0.550107\n",
       "17        0.4          150          9  0.561197  0.568341  0.551812"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_rf.to_csv('result_rf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gb = []\n",
    "\n",
    "for size in [0.3,0.4]:\n",
    "    for n in [500,700,900]:\n",
    "        for m in [1,2]:\n",
    "            for l in [0.01,0.1]:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    x_train_test, y_train_test, test_size = size, random_state = 0)\n",
    "                model = GradientBoostingClassifier(n_estimators = n, max_depth = m, learning_rate = l)\n",
    "                clf = model.fit(X_train, y_train)\n",
    "\n",
    "                y_train_hat = clf.predict_proba(X_train)\n",
    "                train = pd.DataFrame(X_train, columns = list(vars_final['variable'].values))\n",
    "                train['fraud_label'] = y_train.values\n",
    "                train['fraud_proba'] = y_train_hat[:,1]\n",
    "                train_fdr = FDR(train)\n",
    "\n",
    "                y_test_hat = clf.predict_proba(X_test)\n",
    "                test = pd.DataFrame(X_test, columns = list(vars_final['variable'].values))\n",
    "                test['fraud_label'] = y_test.values\n",
    "                test['fraud_proba'] = y_test_hat[:,1]\n",
    "                test_fdr = FDR(test)\n",
    "\n",
    "                y_oot_hat = clf.predict_proba(x_oot)\n",
    "                oot = pd.DataFrame(x_oot, columns = list(vars_final['variable'].values))\n",
    "                oot['fraud_label'] = y_oot.values\n",
    "                oot['fraud_proba'] = y_oot_hat[:,1]\n",
    "                oot_fdr = FDR(oot)\n",
    "\n",
    "                dict_gb = dict(test_size = size, num_of_tree = n, max_depth = m, learning_rate = l,\\\n",
    "                                TRAIN = train_fdr, TEST = test_fdr, OOT = oot_fdr)\n",
    "                result_gb.append(dict_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gb = pd.DataFrame(result_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>num_of_tree</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>TRAIN</th>\n",
       "      <th>TEST</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.559409</td>\n",
       "      <td>0.571350</td>\n",
       "      <td>0.544563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.561197</td>\n",
       "      <td>0.571350</td>\n",
       "      <td>0.548827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.558217</td>\n",
       "      <td>0.568584</td>\n",
       "      <td>0.551386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.564653</td>\n",
       "      <td>0.576051</td>\n",
       "      <td>0.551386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.558694</td>\n",
       "      <td>0.572456</td>\n",
       "      <td>0.548401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.560958</td>\n",
       "      <td>0.572179</td>\n",
       "      <td>0.548827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3</td>\n",
       "      <td>700</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.561197</td>\n",
       "      <td>0.572179</td>\n",
       "      <td>0.551386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>700</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.564772</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.553945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3</td>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.558455</td>\n",
       "      <td>0.571903</td>\n",
       "      <td>0.551386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.3</td>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.561077</td>\n",
       "      <td>0.573285</td>\n",
       "      <td>0.550959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.3</td>\n",
       "      <td>900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.560839</td>\n",
       "      <td>0.572732</td>\n",
       "      <td>0.551386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.3</td>\n",
       "      <td>900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.563580</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.556503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.539796</td>\n",
       "      <td>0.543845</td>\n",
       "      <td>0.540299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.562736</td>\n",
       "      <td>0.566900</td>\n",
       "      <td>0.548827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.559938</td>\n",
       "      <td>0.564430</td>\n",
       "      <td>0.551386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.564554</td>\n",
       "      <td>0.570605</td>\n",
       "      <td>0.551386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.4</td>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.559659</td>\n",
       "      <td>0.567106</td>\n",
       "      <td>0.548401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.4</td>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.562736</td>\n",
       "      <td>0.567929</td>\n",
       "      <td>0.548827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.4</td>\n",
       "      <td>700</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.562456</td>\n",
       "      <td>0.566694</td>\n",
       "      <td>0.551386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.4</td>\n",
       "      <td>700</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.566093</td>\n",
       "      <td>0.570811</td>\n",
       "      <td>0.553945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.4</td>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.559799</td>\n",
       "      <td>0.567517</td>\n",
       "      <td>0.549254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.4</td>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.562456</td>\n",
       "      <td>0.566900</td>\n",
       "      <td>0.550533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.4</td>\n",
       "      <td>900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.562037</td>\n",
       "      <td>0.567517</td>\n",
       "      <td>0.550959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.4</td>\n",
       "      <td>900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.565674</td>\n",
       "      <td>0.570811</td>\n",
       "      <td>0.555224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_size  num_of_tree  max_depth  learning_rate     TRAIN      TEST  \\\n",
       "0         0.3          500          1           0.01  0.559409  0.571350   \n",
       "1         0.3          500          1           0.10  0.561197  0.571350   \n",
       "2         0.3          500          2           0.01  0.558217  0.568584   \n",
       "3         0.3          500          2           0.10  0.564653  0.576051   \n",
       "4         0.3          700          1           0.01  0.558694  0.572456   \n",
       "5         0.3          700          1           0.10  0.560958  0.572179   \n",
       "6         0.3          700          2           0.01  0.561197  0.572179   \n",
       "7         0.3          700          2           0.10  0.564772  0.575221   \n",
       "8         0.3          900          1           0.01  0.558455  0.571903   \n",
       "9         0.3          900          1           0.10  0.561077  0.573285   \n",
       "10        0.3          900          2           0.01  0.560839  0.572732   \n",
       "11        0.3          900          2           0.10  0.563580  0.575221   \n",
       "12        0.4          500          1           0.01  0.539796  0.543845   \n",
       "13        0.4          500          1           0.10  0.562736  0.566900   \n",
       "14        0.4          500          2           0.01  0.559938  0.564430   \n",
       "15        0.4          500          2           0.10  0.564554  0.570605   \n",
       "16        0.4          700          1           0.01  0.559659  0.567106   \n",
       "17        0.4          700          1           0.10  0.562736  0.567929   \n",
       "18        0.4          700          2           0.01  0.562456  0.566694   \n",
       "19        0.4          700          2           0.10  0.566093  0.570811   \n",
       "20        0.4          900          1           0.01  0.559799  0.567517   \n",
       "21        0.4          900          1           0.10  0.562456  0.566900   \n",
       "22        0.4          900          2           0.01  0.562037  0.567517   \n",
       "23        0.4          900          2           0.10  0.565674  0.570811   \n",
       "\n",
       "         OOT  \n",
       "0   0.544563  \n",
       "1   0.548827  \n",
       "2   0.551386  \n",
       "3   0.551386  \n",
       "4   0.548401  \n",
       "5   0.548827  \n",
       "6   0.551386  \n",
       "7   0.553945  \n",
       "8   0.551386  \n",
       "9   0.550959  \n",
       "10  0.551386  \n",
       "11  0.556503  \n",
       "12  0.540299  \n",
       "13  0.548827  \n",
       "14  0.551386  \n",
       "15  0.551386  \n",
       "16  0.548401  \n",
       "17  0.548827  \n",
       "18  0.551386  \n",
       "19  0.553945  \n",
       "20  0.549254  \n",
       "21  0.550533  \n",
       "22  0.550959  \n",
       "23  0.555224  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_gb.to_csv('result_gb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ada = []\n",
    "\n",
    "for size in [0.3,0.4]:\n",
    "    for n in [500,700,900]:\n",
    "        for l in [0.01,0.1,1]:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                x_train_test, y_train_test, test_size = size, random_state = 0)\n",
    "            model = AdaBoostClassifier(n_estimators = n, learning_rate = l)\n",
    "            clf = model.fit(X_train, y_train)\n",
    "\n",
    "            y_train_hat = clf.predict_proba(X_train)\n",
    "            train = pd.DataFrame()\n",
    "            train['fraud_label'] = y_train.values\n",
    "            train['fraud_proba'] = y_train_hat[:,1]\n",
    "            train_fdr = FDR(train)\n",
    "\n",
    "            y_test_hat = clf.predict_proba(X_test)\n",
    "            test = pd.DataFrame()\n",
    "            test['fraud_label'] = y_test.values\n",
    "            test['fraud_proba'] = y_test_hat[:,1]\n",
    "            test_fdr = FDR(test)\n",
    "\n",
    "            y_oot_hat = clf.predict_proba(x_oot)\n",
    "            oot = pd.DataFrame()\n",
    "            oot['fraud_label'] = y_oot.values\n",
    "            oot['fraud_proba'] = y_oot_hat[:,1]\n",
    "            oot_fdr = FDR(oot)\n",
    "\n",
    "            dict_ada = dict(test_size = size, num_of_tree = n, learning_rate = l,\\\n",
    "                            TRAIN = train_fdr, TEST = test_fdr, OOT = oot_fdr)\n",
    "            result_ada.append(dict_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ada = pd.DataFrame(result_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>num_of_tree</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>TRAIN</th>\n",
       "      <th>TEST</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.560481</td>\n",
       "      <td>0.573285</td>\n",
       "      <td>0.547548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.563818</td>\n",
       "      <td>0.576327</td>\n",
       "      <td>0.551386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.563699</td>\n",
       "      <td>0.576327</td>\n",
       "      <td>0.550107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>700</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.562150</td>\n",
       "      <td>0.573285</td>\n",
       "      <td>0.550959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>700</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.563818</td>\n",
       "      <td>0.576881</td>\n",
       "      <td>0.550533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>700</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.564891</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.549680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3</td>\n",
       "      <td>900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.562984</td>\n",
       "      <td>0.574392</td>\n",
       "      <td>0.550959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>900</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.563699</td>\n",
       "      <td>0.576604</td>\n",
       "      <td>0.550533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3</td>\n",
       "      <td>900</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.564176</td>\n",
       "      <td>0.576881</td>\n",
       "      <td>0.549680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.559938</td>\n",
       "      <td>0.567929</td>\n",
       "      <td>0.547122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.564275</td>\n",
       "      <td>0.572664</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.564834</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.549680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.4</td>\n",
       "      <td>700</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.562456</td>\n",
       "      <td>0.568753</td>\n",
       "      <td>0.550533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.4</td>\n",
       "      <td>700</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.564275</td>\n",
       "      <td>0.572664</td>\n",
       "      <td>0.551812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.4</td>\n",
       "      <td>700</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.564834</td>\n",
       "      <td>0.572046</td>\n",
       "      <td>0.550107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.4</td>\n",
       "      <td>900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.563855</td>\n",
       "      <td>0.570193</td>\n",
       "      <td>0.550959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.4</td>\n",
       "      <td>900</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.564275</td>\n",
       "      <td>0.572252</td>\n",
       "      <td>0.550959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.4</td>\n",
       "      <td>900</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.564834</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.548827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_size  num_of_tree  learning_rate     TRAIN      TEST       OOT\n",
       "0         0.3          500           0.01  0.560481  0.573285  0.547548\n",
       "1         0.3          500           0.10  0.563818  0.576327  0.551386\n",
       "2         0.3          500           1.00  0.563699  0.576327  0.550107\n",
       "3         0.3          700           0.01  0.562150  0.573285  0.550959\n",
       "4         0.3          700           0.10  0.563818  0.576881  0.550533\n",
       "5         0.3          700           1.00  0.564891  0.575221  0.549680\n",
       "6         0.3          900           0.01  0.562984  0.574392  0.550959\n",
       "7         0.3          900           0.10  0.563699  0.576604  0.550533\n",
       "8         0.3          900           1.00  0.564176  0.576881  0.549680\n",
       "9         0.4          500           0.01  0.559938  0.567929  0.547122\n",
       "10        0.4          500           0.10  0.564275  0.572664  0.552239\n",
       "11        0.4          500           1.00  0.564834  0.571429  0.549680\n",
       "12        0.4          700           0.01  0.562456  0.568753  0.550533\n",
       "13        0.4          700           0.10  0.564275  0.572664  0.551812\n",
       "14        0.4          700           1.00  0.564834  0.572046  0.550107\n",
       "15        0.4          900           0.01  0.563855  0.570193  0.550959\n",
       "16        0.4          900           0.10  0.564275  0.572252  0.550959\n",
       "17        0.4          900           1.00  0.564834  0.571429  0.548827"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_ada.to_csv('result_ada.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
